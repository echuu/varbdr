y_test       = x_test$course
ncol(xtrain_lasso) == ncol(xtest_lasso) # should print TRUE
xtrain_mat = model.matrix( ~ . , xtrain_lasso)[,-1] # 682 x 33
xtest_mat  = model.matrix( ~ . , xtest_lasso)[,-1]  # 338 x 33
set.seed(1)
course_lasso = glmnet(x = xtrain_mat, y = y_train, alpha = 1)
cv_course_lasso = cv.glmnet(x = xtrain_mat, y = y_train, alpha = 1)
(lambda_star0 = cv_course_lasso$lambda.min)      # optimal lambda: 0.1902754
# lasso model coefficients
coeffs_l0 = predict(course_lasso, type = 'coefficients', s = lambda_star0)
lasso_pred0  = predict(course_lasso, s = lambda_star0, newx = xtest_mat)
mean((lasso_pred0 - y_test)^2)                   # TEST MSE: 76.5686
ex_stud = xtrain_mat[1,]
ex_stud
length(ex_stud)
ex_stud[1:length(ex_stud)] = 0
ex_stud
data.frame(1:33, names(ex_stud))
coeffs_l0
coeffs_l0[2:34]
data.frame(names(ex_stud), coeffs_l0[2:34])
ex_stud[c(2, 10, 12, 19, 22, 23, 25, 18)] = 1
ex_stud$must
ex_stud[,'must']
ex_stud['must']
ex_stud['must'] = 13
ex_stud['alg']  = 5
ex_stud['conc'] = 3
lasso_pred = predict(course_lasso, s = lambda_star0, newx = ex_stud,
type = 'response')
length(ex_stud)
x_copy = xtest_mat
x_copy[1,] = ex_stud
head(x_copy)
lasso_pred = predict(course_lasso, s = lambda_star0, newx = x_copy,
type = 'response')
lasso_pred[1] # 74.26082
vars_omit = c(response_vars, all_questions, "comm")
var_names[!(var_names %in% vars_omit)]
var_subset = !(var_names %in% vars_omit)
dim(x_train[,var_subset])                        # X_TRAIN DIM: 682 x 14
# set up xtrain, xtest, ytrain, ytest
xtrain_lasso = x_train[,var_subset]
xtest_lasso  = x_test[,var_subset]
y_train      = x_train$course
y_test       = x_test$course
ncol(xtrain_lasso) == ncol(xtest_lasso) # should print TRUE
xtrain_mat = model.matrix( ~ . , xtrain_lasso)[,-1] # 682 x 33
xtest_mat  = model.matrix( ~ . , xtest_lasso)[,-1]  # 338 x 33
set.seed(1)
pf_lasso = glmnet(x = xtrain_mat, y = as.factor(x_train$pass),
alpha = 1, family = 'binomial')         # fit lasso model
cv_pf_lasso = cv.glmnet(x = xtrain_mat, y = as.factor(x_train$pass),
family = 'binomial', alpha = 1)
lambda_star = cv_pf_lasso$lambda.min               # optimal lambda: 0.01035964
lasso_results = getClassResults(pf_lasso, x_train, x_test, lambda = lambda_star,
xtrain_mat = xtrain_mat, xtest_mat = xtest_mat)
lasso_results$test_balance   # test balanced accuracy  :  0.6962771
lasso_results$test_overall   # test overall accuracy   :  0.8343195
lasso_results$conf_mat       # true values of pass/fail are given by column sums
lasso_pred = predict(course_lasso, s = lambda_star, newx = x_copy,
type = 'response')
lasso_pred[1] # 82.13804
lasso_pred = predict(pf_lasso, s = lambda_star, newx = x_copy,
type = 'response')
lasso_pred[1] # 82.13804
coeffs_lasso
# lasso model coefficients
coeffs_lasso = predict(pf_lasso, type = 'coefficients', s = lambda_star)
coeffs_lasso
x = read.csv("must.csv") # 1020 x 50
# omit 'zip' variable from the grand list of variables because of poor encoding
var_names = c("school",  "course" ,  "class"  , "gender"  , "ethnic" , "major",
"grand" ,  "parent" ,  "emp_on" , "emp_off" , "hrs"    , "ver"  ,
"MQ1"   ,  "MQ2"    ,  "MQ3"    , "MQ4"     , "MQ5"    , "MQ6"  ,
"MQ7"   ,  "MQ8"    ,  "MQ9"    , "MQ10"    , "MQ11"   , "MQ12" ,
"MQ13"  ,  "MQ14"   ,  "MQ15"   , "MQ16"    , "MQ17"   , "MQ18" ,
"MQ19"  ,  "MQ20"   ,  "must"   , "Q1A"     , "Q1C"    , "Q2A"  ,
"Q2C"   ,  "Q3A"    ,  "Q3C"    , "Q4A"     , "Q4C"    , "Q5A"  ,
"Q5C"   ,  "Q6A"    ,  "Q6C"    , "comm"    , "pass"   , "alg"  ,
"conc")
response_vars = c("course", "pass")
x = x[,which(names(x) %in% var_names)] # 1020 x 49
## train/test split --- training set will have 2/3 of the total data
# one of the two is omitted depending on the task (regression/class.)
#    pass       :  calculated using the course average
#    course     :  used to calculate the 'pass' variable
# depending on modeling choice, we can omit
#    (1) alg and conc since they are sum of Q1A to Q6A and Q1C to Q6C
#    (2) must and comm since they are sum of MQ1 to MQ20, Q1A/C to Q6A/C
# transform indicator variables to factors:
# gender, version, MQ1-MQ20, Q1A-Q6C
MUST_q = paste(rep("MQ", 20), 1:20, sep = "")
COMM_q = paste(rep(paste("Q", 1:6, sep = ""), 2),
c(rep("A", 6), rep("C", 6)), sep = "")
all_questions = c(MUST_q, COMM_q)
numer_cols = c("gender", "ver", "pass", all_questions)
x[,numer_cols] = lapply(x[,numer_cols], factor) # numeric indicators -> factor
str(x)
train_test = generateTrainTest(x, seed = 0)
x_train = train_test[[1]]   # 682 x 49
x_test  = train_test[[2]]   # 338 x 49
# in the model_matrix, omit response variables (course, pass), individual q's,
# and 'comm' since we will be using conc + alg instead
vars_omit = c(response_vars, all_questions, "comm")
var_names[!(var_names %in% vars_omit)]
var_subset = !(var_names %in% vars_omit)
dim(x_train[,var_subset])                        # X_TRAIN DIM: 682 x 14
# set up xtrain, xtest, ytrain, ytest
xtrain_lasso = x_train[,var_subset]
xtest_lasso  = x_test[,var_subset]
y_train      = x_train$course
y_test       = x_test$course
ncol(xtrain_lasso) == ncol(xtest_lasso) # should print TRUE
xtrain_mat = model.matrix( ~ . , xtrain_lasso)[,-1] # 682 x 33
xtest_mat  = model.matrix( ~ . , xtest_lasso)[,-1]  # 338 x 33
set.seed(1)
course_lasso = glmnet(x = xtrain_mat, y = y_train, alpha = 1)
cv_course_lasso = cv.glmnet(x = xtrain_mat, y = y_train, alpha = 1)
(lambda_star0 = cv_course_lasso$lambda.min)      # optimal lambda: 0.1902754
# lasso model coefficients
coeffs_l0 = predict(course_lasso, type = 'coefficients', s = lambda_star0)
lasso_pred0  = predict(course_lasso, s = lambda_star0, newx = xtest_mat)
mean((lasso_pred0 - y_test)^2)                   # TEST MSE: 76.5686
# save lasso coefficients to csv
coeffs_out = as.data.frame(as.matrix(round(coeffs_l0, 4)))
setwd("C:/Users/chuu/ChemEd/paper_2")
source("C:/Users/chuu/ChemEd/paper_2/misc.R") # load in the misc.R functions
library(MASS)
library(dplyr)
library(glmnet)
x = read.csv("must.csv") # 1020 x 50
# omit 'zip' variable from the grand list of variables because of poor encoding
var_names = c("school",  "course" ,  "class"  , "gender"  , "ethnic" , "major",
"grand" ,  "parent" ,  "emp_on" , "emp_off" , "hrs"    , "ver"  ,
"MQ1"   ,  "MQ2"    ,  "MQ3"    , "MQ4"     , "MQ5"    , "MQ6"  ,
"MQ7"   ,  "MQ8"    ,  "MQ9"    , "MQ10"    , "MQ11"   , "MQ12" ,
"MQ13"  ,  "MQ14"   ,  "MQ15"   , "MQ16"    , "MQ17"   , "MQ18" ,
"MQ19"  ,  "MQ20"   ,  "must"   , "Q1A"     , "Q1C"    , "Q2A"  ,
"Q2C"   ,  "Q3A"    ,  "Q3C"    , "Q4A"     , "Q4C"    , "Q5A"  ,
"Q5C"   ,  "Q6A"    ,  "Q6C"    , "comm"    , "pass"   , "alg"  ,
"conc")
response_vars = c("course", "pass")
x = x[,which(names(x) %in% var_names)] # 1020 x 49
## train/test split --- training set will have 2/3 of the total data
# one of the two is omitted depending on the task (regression/class.)
#    pass       :  calculated using the course average
#    course     :  used to calculate the 'pass' variable
# depending on modeling choice, we can omit
#    (1) alg and conc since they are sum of Q1A to Q6A and Q1C to Q6C
#    (2) must and comm since they are sum of MQ1 to MQ20, Q1A/C to Q6A/C
# transform indicator variables to factors:
# gender, version, MQ1-MQ20, Q1A-Q6C
MUST_q = paste(rep("MQ", 20), 1:20, sep = "")
COMM_q = paste(rep(paste("Q", 1:6, sep = ""), 2),
c(rep("A", 6), rep("C", 6)), sep = "")
all_questions = c(MUST_q, COMM_q)
numer_cols = c("gender", "ver", "pass", all_questions)
x[,numer_cols] = lapply(x[,numer_cols], factor) # numeric indicators -> factor
str(x)
train_test = generateTrainTest(x, seed = 0)
x_train = train_test[[1]]   # 682 x 49
x_test  = train_test[[2]]   # 338 x 49
vars_omit = c(response_vars, all_questions, "comm")
var_names[!(var_names %in% vars_omit)]
var_subset = !(var_names %in% vars_omit)
dim(x_train[,var_subset])                        # X_TRAIN DIM: 682 x 14
# set up xtrain, xtest, ytrain, ytest
xtrain_lasso = x_train[,var_subset]
xtest_lasso  = x_test[,var_subset]
y_train      = x_train$course
y_test       = x_test$course
ncol(xtrain_lasso) == ncol(xtest_lasso) # should print TRUE
xtrain_mat = model.matrix( ~ . , xtrain_lasso)[,-1] # 682 x 33
xtest_mat  = model.matrix( ~ . , xtest_lasso)[,-1]  # 338 x 33
set.seed(1)
pf_lasso = glmnet(x = xtrain_mat, y = as.factor(x_train$pass),
alpha = 1, family = 'binomial')         # fit lasso model
cv_pf_lasso = cv.glmnet(x = xtrain_mat, y = as.factor(x_train$pass),
family = 'binomial', alpha = 1)
lambda_star = cv_pf_lasso$lambda.min               # optimal lambda: 0.01035964
# predict(pf_lasso, type = 'coefficients', s = lambda_star) # coefficients
lasso_results = getClassResults(pf_lasso, x_train, x_test, lambda = lambda_star,
xtrain_mat = xtrain_mat, xtest_mat = xtest_mat)
lasso_results$test_balance   # test balanced accuracy  :  0.6962771
lasso_results$test_overall   # test overall accuracy   :  0.8343195
lasso_results$conf_mat       # true values of pass/fail are given by column sums
# lasso model coefficients
coeffs_lasso = predict(pf_lasso, type = 'coefficients', s = lambda_star)
# save lasso coefficients to csv
coeffs_out = as.data.frame(as.matrix(round(coeffs_lasso, 4)))
coeffs_lasso
coeffs_lasso
# save lasso coefficients to csv
coeffs_out = as.data.frame(as.matrix(round(coeffs_lasso, 4)))
write.csv(coeffs_out, "model_coeffs/class/pf_lasso.csv")
ex_stud = xtrain_mat[1,]         # extract an example of a student
ex_stud[1:length(ex_stud)] = 0   # reset the entries
ex_stud[c(2, 10, 12, 19, 22, 23, 25, 18)] = 1
ex_stud['must'] = 13
ex_stud['alg']  = 5
ex_stud['conc'] = 3
x_copy = xtest_mat
x_copy[1,] = ex_stud
lasso_pred = predict(pf_lasso, s = lambda_star, newx = x_copy,
type = 'response')
lasso_pred[1] # 82.13804
predict(pf_lasso, s = lambda_star, newx = x_copy,
type = 'probability')[1]
predict(pf_lasso, s = lambda_star, newx = x_copy,
type = 'link')[1]
logodds = predict(pf_lasso, s = lambda_star, newx = x_copy,
type = 'link')[1]
exp(logodds) / (1 + exp(logodds))
data.frame(ex_stud)
data.frame(ex_stud, coeffs_lasso[2:34])
coeffs_out
vars_omit = c(response_vars, all_questions, "comm")
var_names[!(var_names %in% vars_omit)]
var_subset = !(var_names %in% vars_omit)
dim(x_train[,var_subset])                        # X_TRAIN DIM: 682 x 14
# set up xtrain, xtest, ytrain, ytest
xtrain_lasso = x_train[,var_subset]
xtest_lasso  = x_test[,var_subset]
y_train      = x_train$course
y_test       = x_test$course
ncol(xtrain_lasso) == ncol(xtest_lasso) # should print TRUE
xtrain_mat = model.matrix( ~ . , xtrain_lasso)[,-1] # 682 x 33
xtest_mat  = model.matrix( ~ . , xtest_lasso)[,-1]  # 338 x 33
set.seed(1)
course_lasso = glmnet(x = xtrain_mat, y = y_train, alpha = 1)
cv_course_lasso = cv.glmnet(x = xtrain_mat, y = y_train, alpha = 1)
(lambda_star0 = cv_course_lasso$lambda.min)      # optimal lambda: 0.1902754
# lasso model coefficients
coeffs_l0 = predict(course_lasso, type = 'coefficients', s = lambda_star0)
lasso_pred0  = predict(course_lasso, s = lambda_star0, newx = xtest_mat)
mean((lasso_pred0 - y_test)^2)                   # TEST MSE: 76.5686
# save lasso coefficients to csv
coeffs_out = as.data.frame(as.matrix(round(coeffs_l0, 4)))
coeffs_out
predict(course_lasso, s = lambda_star0, newx = xtest_mat)
predict(course_lasso, type = 'coefficients', s = lambda_star0)
coeffs_lasso
source("C:/Users/chuu/varbdr/code/globals.R")
setwd(HOME_DIR)
source(DP_BDR)
source(DENSITY)
setwd("C:/Users/chuu/varbdr/code/cpp_code")
source("C:/Users/chuu/varbdr/code/cov_dep/misc.R")
source("debug_funcs.R")
N = 100
K = 3
D = 1
synth_data_1d = r_dpmix2(N)
y      = synth_data_1d$y
X      = synth_data_1d$X
intercept = FALSE
max_iter = 5000
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
str(theta_cpp)
source(paste(COV_DEP,  INIT_PRIORS,     sep = '/'))
source(paste(COV_DEP,  INIT_VAR_PARAMS, sep = '/'))
source(paste(COV_DEP,  E_STEP,          sep = '/'))
source(paste(COV_DEP,  M_STEP,          sep = '/'))
source(paste(COV_DEP,  ELBO,            sep = '/'))
source(paste(COV_DEP,  MISC_FUNCS,      sep = '/'))
source(paste(HOME_DIR, DENSITY,         sep = '/'))
m_0 = c(colMeans(X))                         # normal params
Lambda_0 = diag(rep(1, ncol(X)))
a_0 = 1
b_0 = 1                             # gamma params
g_0 = 0
Sigma_0 = diag(rep(1, ncol(X)))
tol = 1e-3
VERBOSE = FALSE
# use c++ initializations for these variational parameters
mu_k = theta_cpp$mu_k
m_k  = theta_cpp$m_k
prior = initPriors(y, X, K, m_0, Lambda_0, a_0, b_0, g_0, Sigma_0,
max_iter, tol, VERBOSE)
theta = initVarParams_0(y, X, N, D, K, intercept, max_iter, m_k, mu_k)
theta = mStep(theta, prior)
all.equal(theta_cpp$alpha, theta$alpha)
all.equal(theta$xi, theta_cpp$xi)
all.equal(theta$phi, theta_cpp$phi)
all.equal(theta$lambda, theta_cpp$lambda)
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
sourceCpp("matrix_opps.cpp")
getwd()
sourceCpp("matrix_ops.cpp")
sourceCpp("matrix_ops.cpp")
sourceCpp("matrix_ops.cpp")
mat_list_ops(1, 3, c(1, 2, 3))
sourceCpp("getVarParams.cpp")
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
str(theta_cpp)
theta_cpp$Q_k
theta$Q_k
# 2nd half of m-step testing
all.equal(theta_cpp$Q_k_inv, theta$Q_k_inv)
# 2nd half of m-step testing
checkEqual(theta_cpp$Q_k_inv, theta$Q_k_inv)
Q_k[[1]]
theta$Q_k]]1
theta$Q_k[[1]]
all.equal(theta$Q_k[[1]], theta_cpp$Q_k[[1]])
theta_cpp$Q_k
theta_cpp$Q_k[[1]]
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
str(theta_cpp)
all.equal(theta_cpp$m_k, theta$m_k)
all.equal(theta_cpp$mu_k, theta$mu_k)
all.equal(theta_cpp$a_k, theta$a_k)
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
str(theta_cpp)
str(theta)
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
str(theta_cpp)
str(theta)
m_0 = c(colMeans(X))                         # normal params
Lambda_0 = diag(rep(1, ncol(X)))
a_0 = 1
b_0 = 1                             # gamma params
g_0 = 0
Sigma_0 = diag(rep(1, ncol(X)))
tol = 1e-3
VERBOSE = FALSE
# use c++ initializations for these variational parameters
mu_k = theta_cpp$mu_k
m_k  = theta_cpp$m_k
prior = initPriors(y, X, K, m_0, Lambda_0, a_0, b_0, g_0, Sigma_0,
max_iter, tol, VERBOSE)
theta = initVarParams_0(y, X, N, D, K, intercept, max_iter, m_k, mu_k)
theta = mStep(theta, prior)
str(theta)
all.equal(theta_cpp$a_k, theta$a_k)
theta$b_k
theta_cpp$b_k
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
str(theta_cpp)
str(theta)
head(theta$lambda)
head(theta_cpp$lambda)
source(paste(COV_DEP,  INIT_PRIORS,     sep = '/'))
source(paste(COV_DEP,  INIT_VAR_PARAMS, sep = '/'))
source(paste(COV_DEP,  E_STEP,          sep = '/'))
source(paste(COV_DEP,  M_STEP,          sep = '/'))
source(paste(COV_DEP,  ELBO,            sep = '/'))
source(paste(COV_DEP,  MISC_FUNCS,      sep = '/'))
source(paste(HOME_DIR, DENSITY,         sep = '/'))
m_0 = c(colMeans(X))                         # normal params
Lambda_0 = diag(rep(1, ncol(X)))
a_0 = 1
b_0 = 1                             # gamma params
g_0 = 0
Sigma_0 = diag(rep(1, ncol(X)))
tol = 1e-3
VERBOSE = FALSE
# use c++ initializations for these variational parameters
mu_k = theta_cpp$mu_k
m_k  = theta_cpp$m_k
prior = initPriors(y, X, K, m_0, Lambda_0, a_0, b_0, g_0, Sigma_0,
max_iter, tol, VERBOSE)
theta = initVarParams_0(y, X, N, D, K, intercept, max_iter, m_k, mu_k)
theta = mStep(theta, prior)
head(theta$lambda)
head(theta_cpp$lambda)
source("C:/Users/chuu/varbdr/code/globals.R")
setwd(HOME_DIR)
source(DP_BDR)
source(DENSITY)
setwd("C:/Users/chuu/varbdr/code/cpp_code")
source("C:/Users/chuu/varbdr/code/cov_dep/misc.R")
source("debug_funcs.R")
N = 100
K = 3
D = 1
synth_data_1d = r_dpmix2(N)
y      = synth_data_1d$y
X      = synth_data_1d$X
intercept = FALSE
max_iter = 5000
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
str(theta_cpp)
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
str(theta_cpp)
head(theta_cpp$lambda)
# use c++ initializations for these variational parameters
mu_k = theta_cpp$mu_k
mu_k
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
str(theta_cpp)
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
str(theta_cpp)
mu_k = theta_cpp$mu_k
m_k  = theta_cpp$m_k
prior = initPriors(y, X, K, m_0, Lambda_0, a_0, b_0, g_0, Sigma_0,
max_iter, tol, VERBOSE)
theta = initVarParams_0(y, X, N, D, K, intercept, max_iter, m_k, mu_k)
theta = mStep(theta, prior)
str(theta)
str(theta_cp;p)
str(theta_cpp)
str(theta)
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
str(theta_cpp)
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
str(theta_cpp)
head(theta_cpp$lambda)
theta_cpp$alpha
theta$alpha
theta_xi
theta$xi
head(theta$xi)
head(theta_cpp$xi)
head(theta_cpp$lambda)
head(theta$lambda)
str(theta)
str(theta_cpp)
theta$b_k
theta_cpp$b_k
source(paste(COV_DEP,  INIT_PRIORS,     sep = '/'))
source(paste(COV_DEP,  INIT_VAR_PARAMS, sep = '/'))
source(paste(COV_DEP,  E_STEP,          sep = '/'))
source(paste(COV_DEP,  M_STEP,          sep = '/'))
source(paste(COV_DEP,  ELBO,            sep = '/'))
source(paste(COV_DEP,  MISC_FUNCS,      sep = '/'))
source(paste(HOME_DIR, DENSITY,         sep = '/'))
prior = initPriors(y, X, K, m_0, Lambda_0, a_0, b_0, g_0, Sigma_0,
max_iter, tol, VERBOSE)
theta = initVarParams_0(y, X, N, D, K, intercept, max_iter, m_k, mu_k)
theta = mStep(theta, prior)
theta$b_k
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
theta_cpp$b_k
sourceCpp("getVarParams.cpp")
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
m_0
t(m_0) * Lambda_0 * m_0
prior$m0_Lambda0_m0
sourceCpp("getVarParams.cpp")
sourceCpp("getVarParams.cpp")
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
str(theta_cpp)
theta$b_k
Lambda_0 * m_0
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
theta_cpp$b_k
theta$b_k
source(paste(COV_DEP,  INIT_PRIORS,     sep = '/'))
source(paste(COV_DEP,  INIT_VAR_PARAMS, sep = '/'))
source(paste(COV_DEP,  E_STEP,          sep = '/'))
source(paste(COV_DEP,  M_STEP,          sep = '/'))
source(paste(COV_DEP,  ELBO,            sep = '/'))
source(paste(COV_DEP,  MISC_FUNCS,      sep = '/'))
source(paste(HOME_DIR, DENSITY,         sep = '/'))
m_0 = c(colMeans(X))                         # normal params
Lambda_0 = diag(rep(1, ncol(X)))
a_0 = 1
b_0 = 1                             # gamma params
g_0 = 0
Sigma_0 = diag(rep(1, ncol(X)))
tol = 1e-3
VERBOSE = FALSE
# use c++ initializations for these variational parameters
prior = initPriors(y, X, K, m_0, Lambda_0, a_0, b_0, g_0, Sigma_0,
max_iter, tol, VERBOSE)
theta = initVarParams_0(y, X, N, D, K, intercept, max_iter, m_k, mu_k)
theta = mStep(theta, prior)
str(theta)
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
sourceCpp("getVarParams.cpp")
theta_cpp = testConstructor(y, X, N, D, K, intercept, max_iter)
str(theta_cpp)
all.equal(theta_cpp$a_k, theta$a_k)
all.equal(theta_cpp$b_k, theta$b_k)
all.equal(theta_cpp$m_k, theta$m_k)
all.equal(theta_cpp$mu_k, theta$mu_k)
all.equal(theta_cpp$alpha, theta$alpha)
all.equal(theta$xi, theta_cpp$xi)
all.equal(theta$phi, theta_cpp$phi)
all.equal(theta$lambda, theta_cpp$lambda)
prior = initPriors(y, X, K, m_0, Lambda_0, a_0, b_0, g_0, Sigma_0,
max_iter, tol, VERBOSE)
theta = initVarParams_0(y, X, N, D, K, intercept, max_iter, m_k, mu_k)
# one iteration of m-step performance
microbenchmark(testConstructor(y, X, N, D, K, intercept, max_iter),
mStep(theta, prior))
12979 / 347
