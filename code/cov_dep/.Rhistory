?load
load("testsavefile.RData")
paste('test', 'save', 'file', '.RData', sep = '')
setwd("~/varbdr/code/cov_dep")
# generate data ----------------------------------------------------------------
N        = 100  # number of observations
D        = 2    # number of covariates
K        = 5    # number of clusters
max_iter = 200  # max number of iterations
tol = 1e-4
VERBOSE = TRUE
# generate X1,...,Xp ~ Unif[0.05, 0.95]
## initialize storage for response, covariates
y = numeric(N)       # (N x 1) vector of response variables
X = matrix(0, N, D)  # (N x D) matrix; covariates for y_n are stored row-wise
shape_mat = matrix(0, N, 2) # hold shape parameters for beta distribution for
# each observation (Y_n, X_n)
## generate data ---------------------------------------------------------------
for (n in 1:N) {
# X_n = (X_n1, X_n2, ... , X_np) ~ Unif [0.05, 0.95]^p
X[n,] = runif(D, 0.05, 0.95) # could generate all covariates at once,
# but this seems a little more intuitive
# store shape parameters for beta distribution
shape_mat[n, 1] = 4 * X[n, 1] + 3 * X[n, 2]^2
shape_mat[n, 2] = 10 * X[n, 2]
# y_n ~ Beta(shape1, shape2)
y[n] = rbeta(1, shape1 = shape_mat[n,1], shape2 = shape_mat[n, 2])
}
# test functions (covariate-dependent) -----------------------------------------
source("initVarParams.R")
## prior parameters
m_0 = c(colMeans(X))
Lambda_0 = diag(rep(1, ncol(X)))
a_0 = 1
b_0 = 1
g_0 = rep(0, ncol(X))
Sigma_0 = diag(rep(1, ncol(X)))
# initPriors() function tested and works
prior = initPriors(y, X, K, m_0, Lambda_0, a_0, b_0, g_0, Sigma_0,
max_iter, tol, VERBOSE)
# initVarParams() function tested and works
theta = initVarParams(y, X, N, D, K, max_iter)
source("eStep.R")
theta_estep = eStep(theta, prior)
# currently testing functions below --------------------------------------------
source("mStep.R")
theta = mStep(theta, prior)
# test functions (covariate-dependent) -----------------------------------------
source("initPriors.R")
# initPriors() function tested and works
prior = initPriors(y, X, K, m_0, Lambda_0, a_0, b_0, g_0, Sigma_0,
max_iter, tol, VERBOSE)
# initVarParams() function tested and works
theta = initVarParams(y, X, N, D, K, max_iter)
source("eStep.R")
theta_estep = eStep(theta, prior)
source("mStep.R")
theta = mStep(theta, prior)
X[n,] %*% theta$V_inv[,,k] %*% t(X[n,])
X[n,] %*% theta$V_k_inv[,,k] %*% t(X[n,])
k
k = 1
X[n,] %*% theta$V_k_inv[,,k] %*% t(X[n,])
dim(X)
dim(theta$V_k_inv[,,k])
t(X[n,]) %*% theta$V_k_inv[,,k] %*% X[n,]
quadMult(X[n,], theta$V_k_inv)
quadMult(X[n,], theta$V_k_inv[,,k])
# initialize the 7 expectations to be computed
e_ln_p_y = e_ln_p_z = e_ln_p_gamma = e_ln_p_beta_tau = 0
e_ln_q_z = e_ln_q_beta_tau = e_ln_q_gamma = 0
X = prior$X
y = prior$y
N = prior$N
D = prior$D
K = prior$K
# commonly computed terms
psi_a = digamma(theta$a_k)    # (K x 1)
psi_b = digamma(theta$b_k)    # (K x 1)
ak_bk = theta$a_k / theta$b_k # (K x 1) : a_k / b_k, elementwise division
e1 = numeric(N)
for (n in 1:N) {
x_Vinv_x = numeric(K)
for (k in 1:K) {
x_Vinv_x[k] = quadMult(X[n,], theta$V_k_inv[,,k]) # x_n'V_k^{-1}x_n
} # end of inner for()
# perform the inner k-summation
e1[n] = sum(theta$r_nk[n,] *
(log(2 * pi) - psi_a + psi_b + x_Vinv_x +
ak_bk * (y[n] - t(X[n,] %*% theta$m_k))^2))
}
e_ln_p_y = -0.5 * sum(e1)
e_ln_p_y
x_Vinv_x
theta$r_nk[n,]
e2 = numeric(K)
for (k in 1:K) {
# exchange the summations; perform the inner n-summation
e2[k] = sum(theta$r_nk[,k] * (X_mu[,k] - theta$alpha - theta$phi))
}
e_ln_p_z = sum(e2) # outer k-summation
X_mu  = X %*% theta$mu_k      # (N x K) : [Xmu_1, Xmu_2, ... , Xmu_K]
e2 = numeric(K)
for (k in 1:K) {
# exchange the summations; perform the inner n-summation
e2[k] = sum(theta$r_nk[,k] * (X_mu[,k] - theta$alpha - theta$phi))
}
e_ln_p_z = sum(e2) # outer k-summation
theta$mu_k
theta$m_k
loop_result = loop_result + t(theta$m_k) %*% theta$m_k
loop_result = 0
for (k in 1:K) {
loop_result = loop_result + t(theta$m_k) %*% theta$m_k
}
loop_result = 0
for (k in 1:K) {
loop_result = loop_result + t(theta$m_k[,k]) %*% theta$m_k[,k]
}
loop_result
sum(theta$m_k^2)
setwd("~/varbdr/code/cov_indep")
library(ggplot2)
N = 100  # number of observations
D = 2    # number of covariates
K = 5    # number of clusters
# generate X1,...,Xp ~ Unif[0.05, 0.95]
## initialize storage for response, covariates
y = numeric(N)       # (N x 1) vector of response variables
X = matrix(0, N, D)  # (N x D) matrix; covariates for y_n are stored row-wise
shape_mat = matrix(0, N, 2) # hold shape parameters for beta distribution for
# each observation (Y_n, X_n)
## generate data
for (n in 1:N) {
# X_n = (X_n1, X_n2, ... , X_np) ~ Unif [0.05, 0.95]^p
X[n,] = runif(D, 0.05, 0.95) # could generate all covariates at once,
# but this seems a little more intuitive
# store shape parameters for beta distribution
shape_mat[n, 1] = 4 * X[n, 1] + 3 * X[n, 2]^2
shape_mat[n, 2] = 10 * X[n, 2]
# y_n ~ Beta(shape1, shape2)
y[n] = rbeta(1, shape1 = shape_mat[n,1], shape2 = shape_mat[n, 2])
}
y_grid = seq(0, 1, len = 500)
run = function() {
source("varbdr.R")              # load the CAVI algorithm for BDR
theta = varbdr(y = y, X = X, K)    # run algorithm
return(theta)
}
theta = run()                   # run algorithm
# variational parameters after CAVI finishes
theta$alpha_k
theta$m_k
theta$tau_k
theta$a_k
theta$b_k
source("approxDensity.R")
n = 10
params = list(shape1 = shape_mat[n,1], shape2 = shape_mat[n,2])
p1 = plotDensities(y_grid, X[n,], dbeta, params, p_y, theta, prior, K)
p1
n = 73
params = list(shape1 = shape_mat[n,1], shape2 = shape_mat[n,2])
p1 = plotDensities(y_grid, X[n,], dbeta, params, p_y, theta, prior, K)
p1
n = 7
params = list(shape1 = shape_mat[n,1], shape2 = shape_mat[n,2])
p1 = plotDensities(y_grid, X[n,], dbeta, params, p_y, theta, prior, K)
p1
t(diff[,k]) %*% prior$Lambda_0 %*% diff[,k]
diff = sweep(theta$m_k, MARGIN = 1, STATS = prior$m_0, FUN = '-')  # (D x K)
t(diff[,k]) %*% prior$Lambda_0 %*% diff[,k]
quadMult(diff[,k], prior$Lambda_0)
e6_k = (0.5 * D + theta$a_k - 1) * (psi_a - psi_b) +
theta$a_k * log(theta$b_k) - theta$a_k - lgamma(theta$a_k)  # (K x 1)
for (k in 1:K) {
e6_k[k] = e6_k[k] + log(det(theta$V_k[,,k]))
}
e_ln_q_beta_tau = sum(e6_k) - 0.5 * K * D * (log(2 * pi) + 1)
e_ln_q_beta_tau
e7 = - 0.5 * K * D * (log(2 * pi) + 1)
for (k in 1:K) {
e7 = e7 + log(det(theta$Q_k))
}
e_ln_q_gamma = e7
e7 = - 0.5 * K * D * (log(2 * pi) + 1)
for (k in 1:K) {
e7 = e7 + log(det(theta$Q_k[,,k]))
}
e_ln_q_gamma = e7
theta$Q_k
# generate data ----------------------------------------------------------------
N        = 100  # number of observations
D        = 2    # number of covariates
K        = 5    # number of clusters
max_iter = 200  # max number of iterations
tol = 1e-4
VERBOSE = TRUE
# generate X1,...,Xp ~ Unif[0.05, 0.95]
## initialize storage for response, covariates
y = numeric(N)       # (N x 1) vector of response variables
X = matrix(0, N, D)  # (N x D) matrix; covariates for y_n are stored row-wise
shape_mat = matrix(0, N, 2) # hold shape parameters for beta distribution for
# each observation (Y_n, X_n)
## generate data ---------------------------------------------------------------
for (n in 1:N) {
# X_n = (X_n1, X_n2, ... , X_np) ~ Unif [0.05, 0.95]^p
X[n,] = runif(D, 0.05, 0.95) # could generate all covariates at once,
# but this seems a little more intuitive
# store shape parameters for beta distribution
shape_mat[n, 1] = 4 * X[n, 1] + 3 * X[n, 2]^2
shape_mat[n, 2] = 10 * X[n, 2]
# y_n ~ Beta(shape1, shape2)
y[n] = rbeta(1, shape1 = shape_mat[n,1], shape2 = shape_mat[n, 2])
}
# test functions (covariate-dependent) -----------------------------------------
source("initPriors.R")
source("initVarParams.R")
## prior parameters
m_0 = c(colMeans(X))
Lambda_0 = diag(rep(1, ncol(X)))
a_0 = 1
b_0 = 1
g_0 = rep(0, ncol(X))
Sigma_0 = diag(rep(1, ncol(X)))
# initPriors() function tested and works
prior = initPriors(y, X, K, m_0, Lambda_0, a_0, b_0, g_0, Sigma_0,
max_iter, tol, VERBOSE)
# initVarParams() function tested and works
theta = initVarParams(y, X, N, D, K, max_iter)
source("eStep.R")
theta_estep = eStep(theta, prior)
# currently testing functions below --------------------------------------------
source("mStep.R")
theta = mStep(theta, prior)
theta$Q_k
setwd("~/varbdr/code/cov_dep")
# generate data ----------------------------------------------------------------
N        = 100  # number of observations
D        = 2    # number of covariates
K        = 5    # number of clusters
max_iter = 200  # max number of iterations
tol = 1e-4
VERBOSE = TRUE
# generate X1,...,Xp ~ Unif[0.05, 0.95]
## initialize storage for response, covariates
y = numeric(N)       # (N x 1) vector of response variables
X = matrix(0, N, D)  # (N x D) matrix; covariates for y_n are stored row-wise
shape_mat = matrix(0, N, 2) # hold shape parameters for beta distribution for
# each observation (Y_n, X_n)
## generate data ---------------------------------------------------------------
for (n in 1:N) {
# X_n = (X_n1, X_n2, ... , X_np) ~ Unif [0.05, 0.95]^p
X[n,] = runif(D, 0.05, 0.95) # could generate all covariates at once,
# but this seems a little more intuitive
# store shape parameters for beta distribution
shape_mat[n, 1] = 4 * X[n, 1] + 3 * X[n, 2]^2
shape_mat[n, 2] = 10 * X[n, 2]
# y_n ~ Beta(shape1, shape2)
y[n] = rbeta(1, shape1 = shape_mat[n,1], shape2 = shape_mat[n, 2])
}
# test functions (covariate-dependent) -----------------------------------------
source("initPriors.R")
source("initVarParams.R")
## prior parameters
m_0 = c(colMeans(X))
Lambda_0 = diag(rep(1, ncol(X)))
a_0 = 1
b_0 = 1
g_0 = rep(0, ncol(X))
Sigma_0 = diag(rep(1, ncol(X)))
# initPriors() function tested and works
prior = initPriors(y, X, K, m_0, Lambda_0, a_0, b_0, g_0, Sigma_0,
max_iter, tol, VERBOSE)
# initVarParams() function tested and works
theta = initVarParams(y, X, N, D, K, max_iter)
source("eStep.R")
theta_estep = eStep(theta, prior)
# currently testing functions below --------------------------------------------
source("mStep.R")
theta = mStep(theta, prior)
theta$Q_k
theta$Q_k_inv
# initialize the 7 expectations to be computed
e_ln_p_y = e_ln_p_z = e_ln_p_gamma = e_ln_p_beta_tau = 0
e_ln_q_z = e_ln_q_beta_tau = e_ln_q_gamma = 0
X = prior$X
y = prior$y
N = prior$N
D = prior$D
K = prior$K
# commonly computed terms
psi_a = digamma(theta$a_k)    # (K x 1)
psi_b = digamma(theta$b_k)    # (K x 1)
ak_bk = theta$a_k / theta$b_k # (K x 1) : a_k / b_k, elementwise division
X_mu  = X %*% theta$mu_k      # (N x K) : [Xmu_1, Xmu_2, ... , Xmu_K]
# alpha, xi, phi, related quantities ---- calculations moved to mStep.R
# alpha = numeric(N)                   # (N x 1)
# xi    = matrix(0, N, K)              # (N x K)
# phi   = numeric(N)                   # (N x 1)
# compute 7 expectations ---------------------------------------------------
# (1) E [ ln p(y | X, beta, tau, Z) ] --------------------------------------
e1 = numeric(N)
for (n in 1:N) {
x_Vinv_x = numeric(K)
for (k in 1:K) {
x_Vinv_x[k] = quadMult(X[n,], theta$V_k_inv[,,k]) # x_n'V_k^{-1}x_n
} # end of inner for()
# perform the inner k-summation
e1[n] = sum(theta$r_nk[n,] *
(log(2 * pi) - psi_a + psi_b + x_Vinv_x +
ak_bk * (y[n] - t(X[n,] %*% theta$m_k))^2))
}
e_ln_p_y = -0.5 * sum(e1)
# (2) E [ ln p(Z | X, gamma) ] ---------------------------------------------
e2 = numeric(K)
for (k in 1:K) {
# exchange the summations; perform the inner n-summation
e2[k] = sum(theta$r_nk[,k] * (X_mu[,k] - theta$alpha - theta$phi))
}
e_ln_p_z = sum(e2) # outer k-summation
# (3) E [ ln p(gamma) ] ----------------------------------------------------
e_ln_p_gamma = - 0.5 * K * D * log(2 * pi) - 0.5 * sum(theta$mu_k^2)
# (4) E [ ln p(beta, tau) ] ------------------------------------------------
e3 = sum((prior$a_0 + 0.5 * D - 1) * (psi_a - psi_b)) -
K * (0.5 * D * log(2 * pi) - log(det(prior$Lambda_0)) -
prior$a_0 * log(prior$b_0) + lgamma(prior$a_0))
diff = sweep(theta$m_k, MARGIN = 1, STATS = prior$m_0, FUN = '-')  # (D x K)
e3_diff_k  = numeric(K)  # store (m_k - m_0)' Lambda_0 (m_k - m_0)
e3_trace_k = numeric(K)  # store trace(Lambda_0 V_K^{-1})
for (k in 1:K) {
e3_diff_k[k]  = quadMult(diff[,k], prior$Lambda_0)
e3_trace_k[k] = matrix.trace(prior$Lambda_0 %*% theta$V_k_inv[,,k])
}
e3_diff_k = ak_bk * (e3_diff_k + prior$b_0) # element-wise multiplication
e_ln_p_beta_tau = e3 - 0.5 * sum(e3_diff_k + e3_trace_k)
# (5) E [ ln q(Z) ] --------------------------------------------------------
e_ln_q_z = sum(theta$r_nk * theta$log_r_nk) # sum over (N x K) matrix
# (6) E [ ln q(beta, tau) ] ------------------------------------------------
e6_k = (0.5 * D + theta$a_k - 1) * (psi_a - psi_b) +
theta$a_k * log(theta$b_k) - theta$a_k - lgamma(theta$a_k)  # (K x 1)
for (k in 1:K) {
e6_k[k] = e6_k[k] + log(det(theta$V_k[,,k]))
}
e_ln_q_beta_tau = sum(e6_k) - 0.5 * K * D * (log(2 * pi) + 1)
e7 = - 0.5 * K * D * (log(2 * pi) + 1)
for (k in 1:K) {
e7 = e7 + log(det(theta$Q_k[,,k]))
}
e_ln_q_gamma = e7
e_ln_q_gamma
# compute the elbo ---------------------------------------------------------
vlb = e_ln_p_y + e_ln_p_z + e_ln_p_gamma + e_ln_p_beta_tau -
e_ln_q_z - e_ln_q_gamma - e_ln_q_beta_tau
vlb
e_ln_p_y
e_ln_p_z
theta$alpha
theta$phi
source("initPriors.R")
source("initVarParams.R")
## prior parameters
m_0 = c(colMeans(X))
Lambda_0 = diag(rep(1, ncol(X)))
a_0 = 1
b_0 = 1
g_0 = rep(0, ncol(X))
Sigma_0 = diag(rep(1, ncol(X)))
# initPriors() function tested and works
prior = initPriors(y, X, K, m_0, Lambda_0, a_0, b_0, g_0, Sigma_0,
max_iter, tol, VERBOSE)
# initVarParams() function tested and works
theta = initVarParams(y, X, N, D, K, max_iter)
theta$alpha
theta$xi
xi      = matrix(1, N, K)          # N x K : nth row used to compute alpha_n
lambda_xi(theta$xi)
lambda_xi(1)
x_grid = seq(0.1, 10, length = 1000)
lambda_x = lambda_xi(x_grid)
xl_df = data.frame(x = x_grid, y = lambda_x)
ggplot(xl_df, aes(x, y)) + geom_point()
ggplot(xl_df, aes(x, y)) + geom_point(size = 0.7)
x_grid = seq(0.1, 100, length = 1000)
lambda_x = lambda_xi(x_grid)
xl_df = data.frame(x = x_grid, y = lambda_x)
ggplot(xl_df, aes(x, y)) + geom_point(size = 0.7)
source("initPriors.R")
source("initVarParams.R")
## prior parameters
m_0 = c(colMeans(X))
Lambda_0 = diag(rep(1, ncol(X)))
a_0 = 1
b_0 = 1
g_0 = rep(0, ncol(X))
Sigma_0 = diag(rep(1, ncol(X)))
# initPriors() function tested and works
prior = initPriors(y, X, K, m_0, Lambda_0, a_0, b_0, g_0, Sigma_0,
max_iter, tol, VERBOSE)
# initVarParams() function tested and works
theta = initVarParams(y, X, N, D, K, max_iter)
source("eStep.R")
theta_estep = eStep(theta, prior)
# currently testing functions below --------------------------------------------
source("mStep.R")
theta = mStep(theta, prior)
theta$alpha
getwd()
source("initPriors.R")
source("initVarParams.R")
## prior parameters
m_0 = c(colMeans(X))
Lambda_0 = diag(rep(1, ncol(X)))
a_0 = 1
b_0 = 1
g_0 = rep(0, ncol(X))
Sigma_0 = diag(rep(1, ncol(X)))
# initPriors() function tested and works
prior = initPriors(y, X, K, m_0, Lambda_0, a_0, b_0, g_0, Sigma_0,
max_iter, tol, VERBOSE)
# initVarParams() function tested and works
theta = initVarParams(y, X, N, D, K, max_iter)
source("eStep.R")
theta_estep = eStep(theta, prior)
# currently testing functions below --------------------------------------------
source("mStep.R")
theta = mStep(theta, prior)
theta$alpha
theta$xi
theta$lambda
source("elbo.R")
theta$L[i] = elbo(theta, prior)
theta$L[i]
# initialize the 7 expectations to be computed
e_ln_p_y = e_ln_p_z = e_ln_p_gamma = e_ln_p_beta_tau = 0
e_ln_q_z = e_ln_q_beta_tau = e_ln_q_gamma = 0
X = prior$X
y = prior$y
N = prior$N
D = prior$D
K = prior$K
# commonly computed terms
psi_a = digamma(theta$a_k)    # (K x 1)
psi_b = digamma(theta$b_k)    # (K x 1)
ak_bk = theta$a_k / theta$b_k # (K x 1) : a_k / b_k, elementwise division
X_mu  = X %*% theta$mu_k      # (N x K) : [Xmu_1, Xmu_2, ... , Xmu_K]
# alpha, xi, phi, related quantities ---- calculations moved to mStep.R
# alpha = numeric(N)                   # (N x 1)
# xi    = matrix(0, N, K)              # (N x K)
# phi   = numeric(N)                   # (N x 1)
# compute 7 expectations ---------------------------------------------------
# (1) E [ ln p(y | X, beta, tau, Z) ] --------------------------------------
e1 = numeric(N)
for (n in 1:N) {
x_Vinv_x = numeric(K)
for (k in 1:K) {
x_Vinv_x[k] = quadMult(X[n,], theta$V_k_inv[,,k]) # x_n'V_k^{-1}x_n
} # end of inner for()
# perform the inner k-summation
e1[n] = sum(theta$r_nk[n,] *
(log(2 * pi) - psi_a + psi_b + x_Vinv_x +
ak_bk * (y[n] - t(X[n,] %*% theta$m_k))^2))
}
e_ln_p_y = -0.5 * sum(e1)
# (2) E [ ln p(Z | X, gamma) ] ---------------------------------------------
e2 = numeric(K)
for (k in 1:K) {
# exchange the summations; perform the inner n-summation
e2[k] = sum(theta$r_nk[,k] * (X_mu[,k] - theta$alpha - theta$phi))
}
e_ln_p_z = sum(e2) # outer k-summation
# (3) E [ ln p(gamma) ] ----------------------------------------------------
e_ln_p_gamma = - 0.5 * K * D * log(2 * pi) - 0.5 * sum(theta$mu_k^2)
# (4) E [ ln p(beta, tau) ] ------------------------------------------------
e3 = sum((prior$a_0 + 0.5 * D - 1) * (psi_a - psi_b)) -
K * (0.5 * D * log(2 * pi) - log(det(prior$Lambda_0)) -
prior$a_0 * log(prior$b_0) + lgamma(prior$a_0))
diff = sweep(theta$m_k, MARGIN = 1, STATS = prior$m_0, FUN = '-')  # (D x K)
e3_diff_k  = numeric(K)  # store (m_k - m_0)' Lambda_0 (m_k - m_0)
e3_trace_k = numeric(K)  # store trace(Lambda_0 V_K^{-1})
for (k in 1:K) {
e3_diff_k[k]  = quadMult(diff[,k], prior$Lambda_0)
e3_trace_k[k] = matrix.trace(prior$Lambda_0 %*% theta$V_k_inv[,,k])
}
e3_diff_k = ak_bk * (e3_diff_k + prior$b_0) # element-wise multiplication
e_ln_p_beta_tau = e3 - 0.5 * sum(e3_diff_k + e3_trace_k)
# (5) E [ ln q(Z) ] --------------------------------------------------------
e_ln_q_z = sum(theta$r_nk * theta$log_r_nk) # sum over (N x K) matrix
# (6) E [ ln q(beta, tau) ] ------------------------------------------------
e6_k = (0.5 * D + theta$a_k - 1) * (psi_a - psi_b) +
theta$a_k * log(theta$b_k) - theta$a_k - lgamma(theta$a_k)  # (K x 1)
for (k in 1:K) {
e6_k[k] = e6_k[k] + log(det(theta$V_k[,,k]))
}
e_ln_q_beta_tau = sum(e6_k) - 0.5 * K * D * (log(2 * pi) + 1)
# (7) E [ ln q(gamma) ] ----------------------------------------------------
e7 = - 0.5 * K * D * (log(2 * pi) + 1)
for (k in 1:K) {
e7 = e7 + log(det(theta$Q_k[,,k]))
}
e_ln_q_gamma = e7
# compute the elbo ---------------------------------------------------------
vlb = e_ln_p_y + e_ln_p_z + e_ln_p_gamma + e_ln_p_beta_tau -
e_ln_q_z - e_ln_q_gamma - e_ln_q_beta_tau
vlb
e_ln_p_y
e_ln_p_z
e_ln_p_gamma
e_ln_p_beta_tau
e_ln_q_z
e_ln_q_gamma
e_ln_q_beta_tau
